{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from folk_tables_utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('xtick', labelsize=12)   \n",
    "plt.rc('ytick', labelsize=12)   \n",
    "plt.rc('legend', fontsize=12)\n",
    "plt.rc('font', family='serif', serif='Palatino')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Dataset objects"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_well_conditioned_covariance_matrix(dim, condition_number=10):\n",
    "    # Generate a random orthogonal matrix using QR decomposition\n",
    "    random_matrix = np.random.randn(dim, dim)\n",
    "    Q, _ = np.linalg.qr(random_matrix)\n",
    "\n",
    "    # Generate random eigenvalues with the desired condition number\n",
    "    min_eigenvalue = 1\n",
    "    max_eigenvalue = min_eigenvalue * condition_number\n",
    "    eigenvalues = np.random.uniform(min_eigenvalue, max_eigenvalue, dim)\n",
    "\n",
    "    # Create a diagonal matrix with the generated eigenvalues\n",
    "    diag_eigenvalues = np.diag(eigenvalues)\n",
    "\n",
    "    # Construct the covariance matrix using the orthogonal matrix and diagonal eigenvalue matrix\n",
    "    covariance_matrix = Q @ diag_eigenvalues @ Q.T\n",
    "\n",
    "    return covariance_matrix\n",
    "\n",
    "def generate_spiked_covariance(n, k, scale=10):\n",
    "    \"\"\"\n",
    "    Generates a full rank covariance matrix with k eigenvalues larger than the rest.\n",
    "\n",
    "    Args:\n",
    "    n (int): The dimensionality of the covariance matrix.\n",
    "    k (int): The number of large eigenvalues.\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: The generated covariance matrix.\n",
    "    \"\"\"\n",
    "    assert k <= n, \"k should be less than or equal to n\"\n",
    "\n",
    "    # Generate n random eigenvalues\n",
    "    eigenvalues = np.random.rand(n)\n",
    "\n",
    "    # Increase the first k eigenvalues\n",
    "    eigenvalues[:k] *= scale\n",
    "\n",
    "    # Generate a random orthogonal matrix\n",
    "    Q, _ = np.linalg.qr(np.random.randn(n, n))\n",
    "\n",
    "    # Generate the covariance matrix\n",
    "    covariance = Q @ np.diag(eigenvalues) @ Q.T\n",
    "\n",
    "    return covariance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "SubmodelClass = LinearRegressionModel\n",
    "ImputedModelClass = ImputedLinearRegressionModel\n",
    "AggregatorClass = MyModelAggregator\n",
    "\n",
    "# Gaussian Dataset\n",
    "all_gaus_cols = np.arange(30)\n",
    "\n",
    "# generate a list of random subsets of all_gaus_cols\n",
    "dataset_gaus_cols_list = [np.random.choice(all_gaus_cols, 20, replace=False) for i in range(10)]\n",
    "dataset_gaus_cols_list += [np.random.choice(all_gaus_cols, 15, replace=False) for i in range(20)]\n",
    "num_datasets = len(dataset_gaus_cols_list)\n",
    "\n",
    "# generate a random symmetric covariance matrix\n",
    "A = np.random.normal(0, 1, (len(all_gaus_cols), 100))\n",
    "cov_matrix = A @ A.T / 100\n",
    "cov_matrix = generate_well_conditioned_covariance_matrix(len(all_gaus_cols), condition_number=100)\n",
    "cov_matrix = generate_spiked_covariance(len(all_gaus_cols), 3, scale=100)\n",
    "\n",
    "theta = np.random.normal(0, 50, len(all_gaus_cols))\n",
    "theta = theta[np.argsort(np.abs(theta))][::-1]\n",
    "sigma = 1.0\n",
    "# assert cov_matrix is symmetric\n",
    "assert np.allclose(cov_matrix, cov_matrix.T)\n",
    "sns.heatmap(np.abs(cov_matrix))\n",
    "#label the axes and legend\n",
    "plt.xlabel('Feature Index', fontsize=20)\n",
    "plt.ylabel('Feature Index', fontsize=20)\n",
    "plt.title('Covariance Matrix Heatmap', fontsize=20)\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"gaussian-plots/gaussian-covariance-matrix-heatmap.pdf\")\n",
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ub_lb_dataset = GaussianDataset(theta=theta, cov=cov_matrix, sigma=sigma, columns=all_gaus_cols, seed=0)\n",
    "og_dataset_list = [GaussianDataset(theta=theta, cov=cov_matrix, sigma=sigma, columns=all_gaus_cols, seed=0) for i in range(num_datasets)]\n",
    "dataset_list = [GaussianDataset(theta=theta, cov=cov_matrix, sigma=sigma, columns=dataset_gaus_cols_list[i], seed=0) for i in range(num_datasets)]\n",
    "og_val_dataset_list = og_dataset_list\n",
    "val_dataset_list = dataset_list\n",
    "og_test_dataset_list = og_dataset_list\n",
    "test_dataset_list = dataset_list\n",
    "\n",
    "all_og_dataset = og_dataset_list[-1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Base Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gaussian_imse_fn(gds):\n",
    "    assert np.array_equal(all_gaus_cols, np.arange(len(gds.theta)))\n",
    "    perm_plus, perm_minus = make_projection_permutation(all_gaus_cols, gds.columns)\n",
    "    perm = perm_plus + perm_minus\n",
    "    cov_mat = gds.cov\n",
    "    Sig_iplus = cov_mat[perm_plus, :][:, perm_plus]\n",
    "    Sig_iplus_inv = np.linalg.inv(Sig_iplus)\n",
    "    Sig_ipm = cov_mat[perm_plus, :][:, perm_minus]\n",
    "    A = Sig_iplus_inv @ Sig_ipm\n",
    "    def gaussian_imse_fn(pred, target):\n",
    "        pred_plus = pred[perm_plus]\n",
    "        pred_minus = pred[perm_minus]\n",
    "\n",
    "        target_plus = target[perm_plus]\n",
    "        target_minus = target[perm_minus]\n",
    "\n",
    "        new_pred = pred_plus + A @ pred_minus\n",
    "        new_target = target_plus + A @ target_minus\n",
    "        v = new_pred - new_target\n",
    "        return v.T @ Sig_iplus @ v / len(v)\n",
    "    return gaussian_imse_fn\n",
    "\n",
    "itds = dataset_list[-1]\n",
    "\n",
    "\n",
    "gaussian_imse_fn = make_gaussian_imse_fn(itds)\n",
    "# gaussian_imse_fn = lambda x, y: -1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_list = [50, 100, 200, 500, 1000]\n",
    "# n_list = [2000, 3000, 4000, 5000, 6000, 7000, 8000, 10000]\n",
    "trial_list = np.arange(20)\n",
    "results_list = []\n",
    "result_cols = ['n', 'dataset_idx', 'num_columns', 'mse', 'abse', 'bool_error', 'trial', 'gaussian_imse']\n",
    "models_list = [SubmodelClass() for _ in range(num_datasets)]\n",
    "for n, trial in tqdm(itertools.product(n_list, trial_list)):\n",
    "    tds = og_test_dataset_list[-1]\n",
    "    cov_matrix, _, _ = compute_covariance_matrix(og_dataset_list[-1])\n",
    "    imputed_baseline = ImputedModelClass(cov_matrix, og_dataset_list[-1].columns)\n",
    "    rw_imputed_baseline = ImputedModelClass(cov_matrix, og_dataset_list[-1].columns)\n",
    "    \n",
    "    losses_list = []\n",
    "    for i in range(num_datasets):\n",
    "        ds = dataset_list[i]\n",
    "        ds.shuffle(seed=trial)\n",
    "\n",
    "        X, y, columns = ds.get_n_samples_numpy(n)\n",
    "        imputed_baseline.impute(X, y, columns)\n",
    "        models_list[i].fit(X, y, columns)\n",
    "\n",
    "        vds = val_dataset_list[i]\n",
    "        mse = compute_error(vds, model=models_list[i], metric=mse_fn, num_samples=10000, imperfect=True)\n",
    "        losses_list.append(mse)\n",
    "        rw_imputed_baseline.impute(X, y, columns, reweight=1 / mse)\n",
    "\n",
    "        gaussian_imse = compute_error(tds, model=models_list[i], metric=gaussian_imse_fn, num_samples=6000, imperfect=False)\n",
    "        mse = compute_error(tds, model=models_list[i], metric=hacky_cov_mse_fn, num_samples=6000, imperfect=False)\n",
    "        abse = compute_error(tds, model=models_list[i], metric=abse_fn, num_samples=6000, imperfect=False)\n",
    "        bool_error = compute_error(tds, model=models_list[i], metric=boolerr_fn, num_samples=6000, imperfect=False)\n",
    "        results_list.append((n, str(i), str(len(columns)), mse, abse, bool_error, trial, gaussian_imse))\n",
    "\n",
    "    agg_model = AggregatorClass()\n",
    "    losses_list = np.array(losses_list)\n",
    "    agg_model.fit(all_columns=og_dataset_list[-1].columns, model_list=models_list, cov_matrix=cov_matrix, losses_list=losses_list)\n",
    "    gaussian_imse = compute_error(tds, model=agg_model, metric=gaussian_imse_fn, num_samples=6000, imperfect=False)\n",
    "    mse = compute_error(tds, model=agg_model, metric=hacky_cov_mse_fn, num_samples=6000, imperfect=False)\n",
    "    abse = compute_error(tds, model=agg_model, metric=abse_fn, num_samples=6000, imperfect=False)\n",
    "    bool_error = compute_error(tds, model=agg_model, metric=boolerr_fn, num_samples=6000, imperfect=False)\n",
    "    results_list.append((n, \"agg\", \"NA\", mse, abse, bool_error, trial, gaussian_imse))\n",
    "\n",
    "    myds = og_dataset_list[-1]\n",
    "    myds.shuffle(seed=trial)\n",
    "    myfeatures, mylabels, mycolumns = myds.get_n_samples_numpy(n)\n",
    "\n",
    "    identity_cov_ds = GaussianDataset(theta=tds.theta, cov=np.eye(tds.theta.shape[0]), sigma=0.0, columns=tds.columns)\n",
    "    naive_agg_model = NaiveAggregator(all_columns=og_dataset_list[-1].columns, model_list=models_list)\n",
    "    gaussian_imse = -1\n",
    "    mse = compute_error(tds, model=naive_agg_model, metric=mse_fn, num_samples=6000, imperfect=True)\n",
    "    #parameter error option\n",
    "    # mse = compute_error(identity_cov_ds, model=naive_agg_model, metric=mse_fn, num_samples=6000, imperfect=True)\n",
    "    abse = compute_error(identity_cov_ds, model=naive_agg_model, metric=abse_fn, num_samples=6000, imperfect=True)\n",
    "    bool_error = compute_error(identity_cov_ds, model=naive_agg_model, metric=boolerr_fn, num_samples=6000, imperfect=True)\n",
    "    results_list.append((n, \"naive_agg\", \"NA\", mse, abse, bool_error, trial, gaussian_imse))\n",
    "\n",
    "    naive_agg_model.fit(myfeatures, mylabels, X_columns=mycolumns)\n",
    "    gaussian_imse = -1\n",
    "    mse = compute_error(tds, model=naive_agg_model, metric=mse_fn, num_samples=6000, imperfect=True)\n",
    "    #parameter error option\n",
    "    # mse = compute_error(identity_cov_ds, model=naive_agg_model, metric=mse_fn, num_samples=6000, imperfect=True)\n",
    "    abse = compute_error(identity_cov_ds, model=naive_agg_model, metric=abse_fn, num_samples=6000, imperfect=True)\n",
    "    bool_error = compute_error(identity_cov_ds, model=naive_agg_model, metric=boolerr_fn, num_samples=6000, imperfect=True)\n",
    "    results_list.append((n, \"opt_naive_agg\", \"NA\", mse, abse, bool_error, trial, gaussian_imse))\n",
    "\n",
    "    imputed_baseline.fit()\n",
    "    gaussian_imse = compute_error(tds, model=imputed_baseline, metric=gaussian_imse_fn, num_samples=6000, imperfect=False)\n",
    "    mse = compute_error(tds, model=imputed_baseline, metric=hacky_cov_mse_fn, num_samples=6000, imperfect=False)\n",
    "    abse = compute_error(tds, model=imputed_baseline, metric=abse_fn, num_samples=6000, imperfect=False)\n",
    "    bool_error = compute_error(tds, model=imputed_baseline, metric=boolerr_fn, num_samples=6000, imperfect=False)\n",
    "    results_list.append((n, \"imputed_baseline\", \"NA\", mse, abse, bool_error, trial, gaussian_imse))\n",
    "\n",
    "    rw_imputed_baseline.fit()\n",
    "    gaussian_imse = compute_error(tds, model=rw_imputed_baseline, metric=gaussian_imse_fn, num_samples=6000, imperfect=False)\n",
    "    mse = compute_error(tds, model=rw_imputed_baseline, metric=hacky_cov_mse_fn, num_samples=6000, imperfect=False)\n",
    "    abse = compute_error(tds, model=rw_imputed_baseline, metric=abse_fn, num_samples=6000, imperfect=False)\n",
    "    bool_error = compute_error(tds, model=rw_imputed_baseline, metric=boolerr_fn, num_samples=6000, imperfect=False)\n",
    "    results_list.append((n, \"rw_imputed_baseline\", \"NA\", mse, abse, bool_error, trial, gaussian_imse))\n",
    "\n",
    "    # HACK to get the right number of columns ######\n",
    "    myds = itds\n",
    "    # myds = dataset_list[0]\n",
    "    # myds = ub_lb_dataset\n",
    "    myds.shuffle(seed=trial)\n",
    "    myfeatures, mylabels, mycolumns = myds.get_n_samples_numpy(n)\n",
    "    # ######\n",
    "\n",
    "    baseline_model = SubmodelClass()\n",
    "    baseline_model.fit(myfeatures, mylabels, mycolumns)\n",
    "    gaussian_imse = compute_error(tds, model=baseline_model, metric=gaussian_imse_fn, num_samples=6000, imperfect=False)\n",
    "    mse = compute_error(tds, model=baseline_model, metric=hacky_cov_mse_fn, num_samples=6000, imperfect=False)\n",
    "    abse = compute_error(tds, model=baseline_model, metric=abse_fn, num_samples=6000, imperfect=False)\n",
    "    bool_error = compute_error(tds, model=baseline_model, metric=boolerr_fn, num_samples=6000, imperfect=False)\n",
    "    results_list.append((n, \"lb_baseline\", \"NA\", mse, abse, bool_error, trial, gaussian_imse))\n",
    "\n",
    "    myfeatures, mylabels, mycolumns = myds.get_n_samples_numpy(num_datasets * n)\n",
    "    baseline_model = SubmodelClass()\n",
    "    baseline_model.fit(myfeatures, mylabels, mycolumns)\n",
    "    gaussian_imse = compute_error(tds, model=baseline_model, metric=gaussian_imse_fn, num_samples=6000, imperfect=False)\n",
    "    mse = compute_error(tds, model=baseline_model, metric=hacky_cov_mse_fn, num_samples=6000, imperfect=False)\n",
    "    abse = compute_error(tds, model=baseline_model, metric=abse_fn, num_samples=6000, imperfect=False)\n",
    "    bool_error = compute_error(tds, model=baseline_model, metric=boolerr_fn, num_samples=6000, imperfect=False)\n",
    "    results_list.append((n, \"ub_baseline\", \"NA\", mse, abse, bool_error, trial, gaussian_imse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results_list, columns=result_cols)\n",
    "og_results_df = results_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = og_results_df.copy()\n",
    "method_name_remap = {\n",
    "    \"agg\": \"Collab\",\n",
    "    \"rw_imputed_baseline\": \"RW-Imputation\",\n",
    "    \"imputed_baseline\": \"Imputation\",\n",
    "    \"naive_agg\": \"Naive-Collab\",\n",
    "    \"opt_naive_agg\": \"Optimized-Naive-Collab\",\n",
    "    \"lb_baseline\": \"Naive-Local\",\n",
    "    \"ub_baseline\": f\"Naive-Local ({num_datasets}x data)\"\n",
    "}\n",
    "results_df = results_df[results_df[\"dataset_idx\"].isin(method_name_remap.keys())]\n",
    "results_df['dataset_idx'] = results_df['dataset_idx'].map(method_name_remap)\n",
    "\n",
    "unique_dataset_idx = results_df['dataset_idx'].unique()\n",
    "\n",
    "# Create a color palette and a marker list\n",
    "palette = dict(zip(unique_dataset_idx, sns.color_palette(n_colors=len(unique_dataset_idx))))\n",
    "markers = dict(zip(unique_dataset_idx, ['o', 'v', '^', '<', '>', '8', 's', 'p', '*', 'h', 'H', 'D', 'd', 'P', 'X'][:len(unique_dataset_idx)]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_methods_list = [\"Collab\", \"RW-Imputation\", \"Imputation\", 'Naive-Local']#, \"ub_baseline\"]\n",
    "plotdf = results_df[results_df['dataset_idx'].isin(plot_methods_list)]\n",
    "\n",
    "# log scale mse column in plotdf\n",
    "plotdf['gaussian_imse'] = np.log10(plotdf['gaussian_imse'])\n",
    "ax = sns.lineplot(x=\"n\", y=\"gaussian_imse\", hue=\"dataset_idx\", data=plotdf, style=\"dataset_idx\", markersize=7, palette=palette, markers=markers)\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles=handles[0:], labels=labels[0:])\n",
    "\n",
    "plt.ylabel(\"Mean Sq. Pred. Err. (log)\", fontsize=20)\n",
    "plt.xlabel(\"number of samples (n)\", fontsize=20)\n",
    "plt.title(\"Local Feature Prediction Error\", fontsize=20)\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"gaussian-plots/gaussian-local-prediction.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_methods_list = [\"Collab\", \"RW-Imputation\", \"Imputation\", \"Naive-Collab\", \"Optimized-Naive-Collab\"]\n",
    "plotdf = results_df[results_df['dataset_idx'].isin(plot_methods_list)]\n",
    "\n",
    "# log scale mse column in plotdf\n",
    "plotdf['mse'] = np.log10(plotdf['mse'])\n",
    "ax=sns.lineplot(x=\"n\", y=\"mse\", hue=\"dataset_idx\", data=plotdf, style=\"dataset_idx\", markersize=7, palette=palette, markers=markers)\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles=handles[0:], labels=labels[0:])\n",
    "plt.ylabel(\"Mean Sq. Pred. Err.\", fontsize=20)\n",
    "plt.xlabel(\"number of samples (n)\", fontsize=20)\n",
    "plt.title(\"Full Feature Prediction Error\", fontsize=20)\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig(\"gaussian-plots/gaussian-full-prediction.pdf\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model_agg_cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
